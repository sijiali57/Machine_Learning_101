{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excerise:\n",
    "Train and fine-tune a Decision Tree for the moons dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.32126048, -0.78908301],\n",
       "        [ 0.34148978,  1.62513477],\n",
       "        [-0.82098625,  0.58287333],\n",
       "        ...,\n",
       "        [ 1.37668036, -0.75882691],\n",
       "        [ 0.33656132,  0.07747864],\n",
       "        [ 0.28068985,  0.0409081 ]]),\n",
       " array([1, 0, 0, ..., 1, 1, 0]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a moons dataset using make_moons(n_smaples=10000, noise =0.4)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html\n",
    "\n",
    "from sklearn import *\n",
    "\n",
    "moon_data=sklearn.datasets.make_moons(n_samples=10000, noise =0.4)\n",
    "moon_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split it into a training set and a test set using train_test_split()\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "X,y = moon_data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 98 candidates, totalling 294 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 294 out of 294 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                            13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                            22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                            31, ...]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use grid searh with cross-validation to find good hyperparameter values for a DecisionTreeClassifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# loop through max_leaf_nodes from 2 to 100 \n",
    "params = {'max_leaf_nodes': list(range(2, 100))}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1, verbose=1, cv=3)\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_leaf_nodes=20, random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the best max_leaf_nodes from the list\n",
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8665"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train it on the full training set using the best max_leaf_nodes, target the accuracy should above 85%\n",
    "\n",
    "best_moon_clf = DecisionTreeClassifier(max_leaf_nodes=20)\n",
    "best_moon_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = best_moon_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8665"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by default the grid_serach_cv will use the best estimator\n",
    "y_pred = grid_search_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 784 candidates, totalling 2352 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2320 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2352 out of 2352 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8665"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# improve the accurary by checking other parameters like \n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 100)),'min_samples_split': list(range(2,10))}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1, verbose=1, cv=3)\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above setting we could see this doesn't help improve the accuracy.... hmmmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excerise 8 - grow a forest\n",
    "a. based on moon dataset generate 1000 subsets of the training set - each subset contains 100 instances selected randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html\n",
    "\n",
    "# class sklearn.model_selection.ShuffleSplit(n_splits=10, *, test_size=None, train_size=None, random_state=None)\n",
    "\n",
    "n_subsets = 1000\n",
    "n_instances = 100\n",
    "\n",
    "mini_sets = []\n",
    "\n",
    "rs = ShuffleSplit(n_splits=n_subsets, test_size=len(X_train) - n_instances, random_state=42)\n",
    "\n",
    "# split(self, X, y=None, groups=None)[source]\n",
    "for mini_train_index, mini_test_index in rs.split(X_train):\n",
    "    X_mini_train = X_train[mini_train_index]\n",
    "    y_mini_train = y_train[mini_train_index]\n",
    "    mini_sets.append((X_mini_train, y_mini_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(mini_sets))\n",
    "print(len(mini_sets[1]))\n",
    "print(len(mini_sets[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Train one decision tree on each subset, using the best hyperparmeter values found above. (in this case, max_leaf_nodes=20, random_state=42 ) Evaluate these 1000 DT on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG:  0.791482\n",
      "MAX:  0.855\n",
      "MIN:  0.6795\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_moon_clf = DecisionTreeClassifier(max_leaf_nodes=20)\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for X_mini_train, y_mini_train in mini_sets:\n",
    "    best_moon_clf.fit(X_mini_train, y_mini_train)\n",
    "    y_pred = best_moon_clf.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print('AVG: ' ,np.mean(accuracy_scores))\n",
    "print('MAX: ' ,np.max(accuracy_scores))\n",
    "print('MIN: ' ,np.min(accuracy_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. For each test set instance, generate the predictions of the 1000 DT and keep only the most frequent prediction (Hint: use SciPy's mode()function). This gives majority-vote predictions over the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG:  0.791453\n",
      "MAX:  0.8525\n",
      "MIN:  0.6795\n"
     ]
    }
   ],
   "source": [
    "# from the above cell, I pre-set the max_leaf_nodes to 20 instead of use the grid_search_cv.best_estimator_, this may cause overfitting\n",
    "\n",
    "from sklearn.base import clone\n",
    "# here instead of set the max leaf, we use grid_search to find the best parameter\n",
    "\n",
    "forest = [clone(grid_search_cv.best_estimator_) for _ in range(n_subsets)] #create 1000 decision trees based best_estimator\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for tree, (X_mini_train, y_mini_train) in zip(forest, mini_sets):\n",
    "    tree.fit(X_mini_train, y_mini_train)\n",
    "    \n",
    "    y_pred = tree.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print('AVG: ' ,np.mean(accuracy_scores))\n",
    "print('MAX: ' ,np.max(accuracy_scores))\n",
    "print('MIN: ' ,np.min(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.empty([n_subsets, len(X_test)], dtype=np.uint8)\n",
    "\n",
    "for tree_index, tree in enumerate(forest):\n",
    "    Y_pred[tree_index] = tree.predict(X_test)\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "y_pred_majority_votes, n_votes = mode(Y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_majority_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[868, 845, 848, ..., 797, 873, 595]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_majority_votes.reshape([-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
